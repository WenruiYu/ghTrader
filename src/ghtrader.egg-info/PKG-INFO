Metadata-Version: 2.4
Name: ghtrader
Version: 0.1.0
Summary: AI-centric SHFE tick research system using TqSdk Pro
Author: ghTrader maintainers
License: MIT
Requires-Python: >=3.10
Description-Content-Type: text/markdown
Requires-Dist: click>=8.1
Requires-Dist: structlog>=24.0
Requires-Dist: numpy>=1.26
Requires-Dist: pandas>=2.0
Requires-Dist: pyarrow>=14.0
Requires-Dist: python-dotenv>=1.0
Requires-Dist: scikit-learn>=1.3
Requires-Dist: torch>=2.2
Provides-Extra: dev
Requires-Dist: pytest>=8.0; extra == "dev"
Requires-Dist: pytest-cov>=5.0; extra == "dev"
Provides-Extra: tabular
Requires-Dist: xgboost>=2.0; extra == "tabular"
Requires-Dist: lightgbm>=4.0; extra == "tabular"
Provides-Extra: sweep
Requires-Dist: ray[tune]>=2.9; extra == "sweep"

# ghTrader

AI-centric SHFE tick trading system for copper (CU), gold (AU), and silver (AG) using TqSdk Pro.

## PRD (single source of truth)

The canonical product/spec/plan for this repo is [`PRD.md`](PRD.md). All future planning should start by reading and updating `PRD.md` before any implementation.

## Project Rules (MUST READ)

### Safety constraints

- **Research-only by default**: no live trading is enabled until explicitly configured
- All order routing code paths are gated behind `GHTRADER_LIVE_ENABLED=true` environment variable
- Default mode is backtest/paper; real orders require explicit enablement

### Data integrity and lineage

- Raw market data is **append-only** in the Parquet lake; never mutate raw data
- Every dataset/build writes a manifest (symbols, date range, schema version, code hash)
- Timestamps are stored in **epoch-nanoseconds** (Beijing time, as provided by TqSdk)

### Reproducibility

- Time-series splits only (walk-forward); no random shuffles across time
- Features and labels must be computable **causally** at tick-time (no future data)
- Each experiment records: config + git commit hash + data manifest IDs + metrics

### AI-centric but production-minded

- Start with strong baselines (Logistic/XGBoost) before deep models
- Training uses GPUs (DDP); backtests are CPU-parallel
- Inference is designed for export (TorchScript/ONNX) for low-latency deployment later

### Performance and scale

- Use **columnar storage** (Parquet/Arrow, ZSTD) partitioned by symbol/date
- Use multi-process / Ray for feature generation and batched backtests
- Avoid single-process bottlenecks

### Engineering hygiene

- Python-only MVP; type hints where they add value
- Keep modules consolidated (minimal file count)
- Add dependencies only when they pay for themselves
- Secrets never committed; credentials come from environment variables / `.env`

---

## Quick start

```bash
# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate

# Install in editable mode (includes vendored tqsdk-python)
pip install -e ./tqsdk-python
pip install -e .

# Configure TqSdk credentials (Pro account with tq_dl required)
# Option 1: Create .env file (recommended)
cp env.example .env
# Edit .env and fill in your credentials

# Option 2: Set environment variables directly
export TQSDK_USER="your_username"
export TQSDK_PASSWORD="your_password"

# Download historical L5 ticks for a symbol and date range
ghtrader download --symbol SHFE.cu2502 --start 2024-01-01 --end 2024-01-31

# Build features and labels
ghtrader build --symbol SHFE.cu2502

# Train baseline model
ghtrader train --model xgboost --symbol SHFE.cu2502

# Train a deep model with DDP across 4 GPUs (recommended on this server)
# (run inside the venv; requires torchrun available in PATH)
torchrun --nproc_per_node=4 -m ghtrader.cli train --model deeplob --symbol SHFE.cu2502 --epochs 50 --batch-size 256 --seq-len 100 --lr 1e-3

# Run backtest
ghtrader backtest --model xgboost --symbol SHFE.cu2502
```

---

## Project structure

```
ghTrader/
  README.md              # This file (project rules + setup)
  pyproject.toml         # Dependencies, entrypoints, formatting
  .gitignore             # Ignore data/, runs/, artifacts/, secrets
  tqsdk-python/          # Vendored TqSdk (do not modify unless patching)
  src/ghtrader/
    __init__.py
    cli.py               # CLI entrypoint (download, record, build, train, backtest, paper)
    tq_ingest.py         # TqSdk integration: historical download + live recorder
    lake.py              # Parquet schema, partitioning, manifest writing/reading
    features.py          # FactorEngine + registry
    labels.py            # Event-time labels, horizons
    models.py            # DeepLOB, Transformer, tabular wrappers
    online.py            # OnlineCalibrator + paper online loop
    eval.py              # Backtest harness + metrics + promotion gates
  data/                  # Parquet lake, manifests (gitignored)
  runs/                  # Configs, metrics, reports (gitignored)
  artifacts/             # Models, scalers, feature specs (gitignored)
```

---

## Data lake schema (L5 ticks)

Partitioning: `data/lake/ticks/symbol=.../date=YYYY-MM-DD/part-....parquet`

Columns:
- `symbol` (string): instrument code (e.g., `SHFE.cu2502`)
- `datetime` (int64): epoch-nanoseconds (Beijing time)
- `last_price`, `average`, `highest`, `lowest` (float64)
- `volume`, `amount`, `open_interest` (float64)
- `bid_price1..5`, `bid_volume1..5` (float64)
- `ask_price1..5`, `ask_volume1..5` (float64)

---

## Labels (event-time, multi-horizon)

- Mid price: `mid = (bid_price1 + ask_price1) / 2`
- Horizons: `N in {10, 50, 200}` ticks (configurable)
- Threshold: `k` ticks (default `k=1`)
- Classes: `{DOWN, FLAT, UP}` based on `mid[t+N] - mid[t]` relative to `k * price_tick`

---

## Models

1. **Baselines**: Logistic regression, XGBoost/LightGBM on engineered factors
2. **DeepLOB-style**: CNN over L5 snapshot + LSTM/GRU over time
3. **Transformer encoder**: longer context, multi-horizon heads
4. **Online calibrator**: stacks deep logits + factor vector; updates intraday via SGD/FTRL

---

## License

MIT
